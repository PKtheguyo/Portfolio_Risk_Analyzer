{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60aacd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "\n",
    "Tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN']\n",
    "Weights = [0.25, 0.25, 0.25, 0.25]\n",
    "Start = '2015-01-01' \n",
    "Years = 5\n",
    "Sims = 5000\n",
    "Trading_Days = 252\n",
    "Block = 10 \n",
    "Seed = 42 \n",
    "Days = int(Years * Trading_Days)\n",
    "rf_annual = 0.04\n",
    "rf_daily = (1 + rf_annual) ** (1/252) - 1\n",
    "\n",
    "prices = yf.download(Tickers,start=Start,auto_adjust=True,progress=False)[\"Close\"].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "pricesSPY = yf.download('SPY', start=Start,auto_adjust=True,progress=False)[\"Close\"].dropna()\n",
    "returnsSPY = pricesSPY.pct_change().dropna()\n",
    "\n",
    "def block_bootstrap_paths(returns_df, weights, days, sims, block, seed):\n",
    "    rng = np.random.default_rng(seed) \n",
    "    ret_np = returns_df.values \n",
    "    T, n = ret_np.shape #T=Number of past days n=number of tickers\n",
    "    w = np.array(weights, dtype=float) #Normalize portfolio weights summing to 1\n",
    "    w /= w.sum()\n",
    "    n_blocks = int(np.ceil(days / block))\n",
    "    paths = np.zeros((days, sims)) #Matrix to store simulated path\n",
    "    sharpe_ratios = np.zeros(sims) \n",
    "    off = np.arange(block) #Create an array for indexing wihthin each block\n",
    "\n",
    "    for s in range(sims):\n",
    "        starts = rng.integers(0, T, size=n_blocks) #Choose random positions for each block\n",
    "        idx = (starts[:, None] + off[None, :]) % T #Block offsets to start pos for full index range\n",
    "        sampled = ret_np[idx.reshape(-1), :][:days] #Pull historical returns and trims\n",
    "        port_daily = sampled @ w \n",
    "        paths[:, s] = np.cumprod(1 + port_daily) #Converts returns to growth \n",
    "        paths[:, s] /= paths[0, s]\n",
    "\n",
    "        excess_returns = port_daily - rf_daily #Computes Sharpe ratio for the path\n",
    "        mean_excess = excess_returns.mean()\n",
    "        std_excess = excess_returns.std()\n",
    "        sharpe_ratios[s] = (mean_excess / std_excess) * np.sqrt(252)\n",
    "\n",
    "    return paths, sharpe_ratios\n",
    "\n",
    "paths, sharpe_ratios = block_bootstrap_paths(returns, Weights, Days, Sims, Block, Seed)\n",
    "pathsSPY, SPYsharpe_ratios = block_bootstrap_paths(returnsSPY, [1.0], Days, Sims, Block, Seed)\n",
    "q = [25,50,75]\n",
    "bands = np.percentile(paths, q, 1) #Computes percentile bands \n",
    "bandsSPY = np.percentile(pathsSPY, q, 1) \n",
    "p25, p50, p75 = np.percentile(paths[-1], q) #Computes percentiles of growth for ending\n",
    "bandsSPY = np.percentile(pathsSPY, q, 1)\n",
    "pS25, pS50, pS75 = np.percentile(pathsSPY[-1], q)\n",
    "\n",
    "ff = pd.read_csv(\"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_daily_CSV.zip\", compression=\"zip\", skiprows=3)\n",
    "date_col = ff.columns[0]\n",
    "ff = ff.rename(columns={date_col: \"Date\"})\n",
    "ff = ff[ff[\"Date\"].astype(str).str.match(r\"^\\d{8}$\")] # Keep only rows that look like (YYYYMMDD)\n",
    "ff[\"Date\"] = pd.to_datetime(ff[\"Date\"], format=\"%Y%m%d\") # Convert date to datetime\n",
    "ff[[\"Mkt-RF\", \"SMB\", \"HML\", \"RF\"]] = ff[[\"Mkt-RF\", \"SMB\", \"HML\", \"RF\"]].astype(float) / 100 # Convert % to decimals\n",
    "ff = ff.set_index(\"Date\").sort_index() # Use Date as index\n",
    "\n",
    "w = np.array(Weights, dtype=float) #Normalize portfolio weights summing to 1\n",
    "w /= w.sum()\n",
    "Rp = returns.dot(w)\n",
    "Rp.name = \"Rp\"\n",
    "data = pd.concat([Rp, ff[['Mkt-RF','SMB','HML','RF']]], axis=1, join=\"inner\").dropna()\n",
    "rows = []\n",
    "for month, grp in data.groupby(data.index.to_period('M')):\n",
    "    y = grp['Rp'] - grp['RF']                   \n",
    "    X = sm.add_constant(grp[['Mkt-RF','SMB','HML']])\n",
    "    m = sm.OLS(y, X).fit()\n",
    "    rows.append({\n",
    "        'Date': month.to_timestamp(),\n",
    "        'Beta_Mkt': m.params['Mkt-RF'],\n",
    "        'Beta_SMB': m.params['SMB'],\n",
    "        'Beta_HML': m.params['HML']\n",
    "    })\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"day\": np.arange(Days),\n",
    "    \"p25\": bands[0],\n",
    "    \"p50\": bands[1],\n",
    "    \"p75\": bands[2]\n",
    "}).to_csv(\"bands.csv\", index=False) \n",
    "\n",
    "pd.DataFrame({\n",
    "    \"day\": np.arange(Days),\n",
    "    \"pS25\": bandsSPY[0],\n",
    "    \"pS50\": bandsSPY[1],\n",
    "    \"pS75\": bandsSPY[2]\n",
    "}).to_csv(\"bandsSPY.csv\", index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Median\": [np.median(sharpe_ratios)],\n",
    "    \"p25\": [np.percentile(sharpe_ratios, 25)],\n",
    "    \"p75\": [np.percentile(sharpe_ratios, 75)],\n",
    "    \"MedianS\": [np.median(SPYsharpe_ratios)],\n",
    "    \"pS25\": [np.percentile(SPYsharpe_ratios, 25)],\n",
    "    \"pS75\": [np.percentile(SPYsharpe_ratios, 75)]\n",
    "}).to_csv(\"Sharpe.csv\", index=False)\n",
    "\n",
    "pd.DataFrame(rows).to_csv(\"3Factor.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
